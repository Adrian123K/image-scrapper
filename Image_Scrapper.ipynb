{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T08:25:36.350520Z",
     "start_time": "2020-06-03T08:25:29.861811Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5 import QtWidgets\n",
    "from PyQt5 import QtGui\n",
    "from PyQt5 import uic\n",
    "from PyQt5 import QtCore\n",
    "from PyQt5.QtCore import pyqtSlot\n",
    "\n",
    "class Image_Scrapper(QtWidgets.QDialog):\n",
    "    def __init__(self, parent=None):\n",
    "        QtWidgets.QDialog.__init__(self, parent)\n",
    "        self.ui = uic.loadUi('Image_Scrapper.ui', self)\n",
    "        self.ui.show()\n",
    "        # 어플리케이션 이름\n",
    "        self.setWindowTitle('Image Scrapper')\n",
    "        # 어플리케이션 아이콘\n",
    "        self.setWindowIcon(QtGui.QIcon('app_icon.jpg'))\n",
    "        # github 이미지\n",
    "        #self.github.setStyleSheet('image:url(github.png);border:0px;')\n",
    "        # 경로 label\n",
    "        self.directory_path.setText('')\n",
    "        # 검색어 textbrowser\n",
    "        self.name.clear()\n",
    "        # 결과 label\n",
    "        self.result.setText('')\n",
    "\n",
    "        # 폴더 선택 버튼 클릭\n",
    "        self.select_folder.clicked.connect(self.select_folder_clicked)\n",
    "        \n",
    "        # 사진 저장 버튼 클릭\n",
    "        self.save.clicked.connect(self.save_clicked)\n",
    "        \n",
    "        \n",
    "        \n",
    "    # 폴더 선택 버튼 클릭 시 동작\n",
    "    def select_folder_clicked(self):\n",
    "        fname = QtWidgets.QFileDialog.getExistingDirectory()\n",
    "        self.directory_path.setText(fname)\n",
    "        \n",
    "    # 사진 저장 버튼 클릭 시 동작\n",
    "    def save_clicked(self):\n",
    "        if self.name.toPlainText():\n",
    "            \n",
    "        else: QtWidgets.QMessageBox.about(self, \"message\", \"clicked\")\n",
    "        self.name.clear()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    w = Image_Scrapper()\n",
    "    app.exec_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "import urllib.request\n",
    "from  bs4 import BeautifulSoup\n",
    "from selenium import webdriver  # 웹 애플리케이션의 테스트를 자동화하기 위한 프레임 워크\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time                     # 중간중간 sleep 을 걸어야 해서 time 모듈 import\n",
    "########################### url 받아오기 ###########################\n",
    "\n",
    "# 웹브라우져로 크롬을 사용할거라서 크롬 드라이버를 다운받아 위의 위치에 둔다\n",
    "# 팬텀 js로 하면 백그라운드로 실행할 수 있음\n",
    "binary = 'c:/chromedriver/chromedriver.exe'\n",
    "\n",
    "# 브라우져를 인스턴스화\n",
    "browser = webdriver.Chrome(binary)\n",
    "\n",
    "# 구글의 이미지 검색 url 받아옴(아무것도 안 쳤을때의 url)\n",
    "browser.get(\"https://www.google.co.kr/imghp?hl=ko&tab=wi&ei=l1AdWbegOcra8QXvtr-4Cw&ved=0EKouCBUoAQ\")\n",
    "\n",
    "# 구글의 이미지 검색에 해당하는 input 창의 id 가 '  ?  ' 임(검색창에 해당하는 html코드를 찾아서 elem 사용하도록 설정)\n",
    "# input창 찾는 방법은 원노트에 있음\n",
    "\n",
    "#elem = browser.find_elements_by_class_name('gLFyf gsfi')\n",
    "\n",
    "elem = browser.find_element_by_xpath(\"//*[@class='gLFyf gsfi']\") \n",
    "\n",
    "\n",
    "\n",
    "########################### 검색어 입력 ###########################\n",
    "\n",
    "# elem 이 input 창과 연결되어 스스로 햄버거를 검색\n",
    "elem.send_keys(\"햄버거\")\n",
    "\n",
    "# 웹에서의 submit 은 엔터의 역할을 함\n",
    "elem.submit()\n",
    "\n",
    "########################### 반복할 횟수 ###########################\n",
    "\n",
    "# 스크롤을 내리려면 브라우져 이미지 검색결과 부분(바디부분)에 마우스 클릭 한번 하고 End키를 눌러야함\n",
    "for i in range(1, 5):\n",
    "    browser.find_element_by_xpath(\"//body\").send_keys(Keys.END)\n",
    "    time.sleep(10)                  # END 키 누르고 내려가는데 시간이 걸려서 sleep 해줌\n",
    "\n",
    "time.sleep(10)                      # 네트워크 느릴까봐 안정성 위해 sleep 해줌\n",
    "html = browser.page_source         # 크롬브라우져에서 현재 불러온 소스 가져옴\n",
    "\n",
    "soup = BeautifulSoup(html, \"lxml\") # html 코드를 검색할 수 있도록 설정\n",
    "\n",
    "########################### 그림파일 저장 ###########################\n",
    "\n",
    "def fetch_list_url():\n",
    "    params = []\n",
    "    imgList = soup.find_all(\"img\", class_=\"rg_i\")  # 구글 이미지 url 이 있는 img 태그의 _img 클래스에 가서\n",
    "    for im in imgList:\n",
    "        try :\n",
    "            params.append(im[\"src\"])                   # params 리스트에 image url 을 담음\n",
    "        except KeyError:\n",
    "            params.append(im[\"data-src\"])\n",
    "    return params\n",
    "\n",
    "# 이미지의 상세 url 의 값이 있는 src 가 없을 경우\n",
    "# data-src 로 가져오시오 ~ \n",
    "\n",
    "\n",
    "def fetch_detail_url():\n",
    "    params = fetch_list_url()\n",
    "\n",
    "    for idx,p in enumerate(params,1):\n",
    "        # 다운받을 폴더경로 입력\n",
    "        urllib.request.urlretrieve(p, \"C:/googleimages/\" + str(idx) + \".jpg\")\n",
    "\n",
    "# enumerate 는 리스트의 모든 요소를 인덱스와 쌍으로 추출\n",
    "# 하는 함수 . 숫자 1은 인덱스를 1부터 시작해라 ~\n",
    "\n",
    "fetch_detail_url()\n",
    "\n",
    "# 끝나면 브라우져 닫기\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "import urllib.request\n",
    "from  bs4 import BeautifulSoup\n",
    "from selenium import webdriver  # 웹 애플리케이션의 테스트를 자동화하기 위한 프레임 워크\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time                     # 중간중간 sleep 을 걸어야 해서 time 모듈 import\n",
    "########################### url 받아오기 ###########################\n",
    "\n",
    "# 웹브라우져로 크롬을 사용할거라서 크롬 드라이버를 다운받아 위의 위치에 둔다\n",
    "# 팬텀 js로 하면 백그라운드로 실행할 수 있음\n",
    "binary = 'c:/chromedriver/chromedriver.exe'\n",
    "\n",
    "# 브라우져를 인스턴스화\n",
    "browser = webdriver.Chrome(binary)\n",
    "\n",
    "# 구글의 이미지 검색 url 받아옴(아무것도 안 쳤을때의 url)\n",
    "browser.get(\"https://search.naver.com/search.naver?where=image&amp;sm=stb_nmr&amp;\")\n",
    "\n",
    "# 구글의 이미지 검색에 해당하는 input 창의 id 가 '  ?  ' 임(검색창에 해당하는 html코드를 찾아서 elem 사용하도록 설정)\n",
    "# input창 찾는 방법은 원노트에 있음\n",
    "\n",
    "#elem = browser.find_elements_by_class_name('gLFyf gsfi')\n",
    "\n",
    "elem = browser.find_element_by_xpath('//*[@id=\"nx_query\"]') \n",
    "\n",
    "\n",
    "\n",
    "########################### 검색어 입력 ###########################\n",
    "\n",
    "# elem 이 input 창과 연결되어 스스로 햄버거를 검색\n",
    "elem.send_keys(\"햄버거\")\n",
    "\n",
    "# 웹에서의 submit 은 엔터의 역할을 함\n",
    "elem.submit()\n",
    "\n",
    "########################### 반복할 횟수 ###########################\n",
    "\n",
    "# 스크롤을 내리려면 브라우져 이미지 검색결과 부분(바디부분)에 마우스 클릭 한번 하고 End키를 눌러야함\n",
    "for i in range(1, 5):\n",
    "    browser.find_element_by_xpath(\"//body\").send_keys(Keys.END)\n",
    "    time.sleep(10)                  # END 키 누르고 내려가는데 시간이 걸려서 sleep 해줌\n",
    "\n",
    "time.sleep(10)                      # 네트워크 느릴까봐 안정성 위해 sleep 해줌\n",
    "html = browser.page_source         # 크롬브라우져에서 현재 불러온 소스 가져옴\n",
    "\n",
    "soup = BeautifulSoup(html, \"lxml\") # html 코드를 검색할 수 있도록 설정\n",
    "\n",
    "########################### 그림파일 저장 ###########################\n",
    "\n",
    "def fetch_list_url():\n",
    "    params = []\n",
    "    imgList = soup.select(\"a.thumb._thumb > img\")  # 구글 이미지 url 이 있는 img 태그의 _img 클래스에 가서\n",
    "    for im in imgList:\n",
    "        try :\n",
    "            params.append(im[\"src\"])                   # params 리스트에 image url 을 담음\n",
    "        except KeyError:\n",
    "            params.append(im[\"data-src\"])\n",
    "    return params\n",
    "\n",
    "# 이미지의 상세 url 의 값이 있는 src 가 없을 경우\n",
    "# data-src 로 가져오시오 ~ \n",
    "\n",
    "\n",
    "def fetch_detail_url():\n",
    "    params = fetch_list_url()\n",
    "\n",
    "    for idx,p in enumerate(params,1):\n",
    "        # 다운받을 폴더경로 입력\n",
    "        urllib.request.urlretrieve(p, \"C:/naverimages/\" + str(idx) + \".jpg\")\n",
    "\n",
    "# enumerate 는 리스트의 모든 요소를 인덱스와 쌍으로 추출\n",
    "# 하는 함수 . 숫자 1은 인덱스를 1부터 시작해라 ~\n",
    "\n",
    "fetch_detail_url()\n",
    "\n",
    "# 끝나면 브라우져 닫기\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "import urllib.request\n",
    "from  bs4 import BeautifulSoup\n",
    "from selenium import webdriver  # 웹 애플리케이션의 테스트를 자동화하기 위한 프레임 워크\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time                     # 중간중간 sleep 을 걸어야 해서 time 모듈 import\n",
    "########################### url 받아오기 ###########################\n",
    "\n",
    "# 웹브라우져로 크롬을 사용할거라서 크롬 드라이버를 다운받아 위의 위치에 둔다\n",
    "# 팬텀 js로 하면 백그라운드로 실행할 수 있음\n",
    "binary = 'c:/chromedriver/chromedriver.exe'\n",
    "\n",
    "# 브라우져를 인스턴스화\n",
    "browser = webdriver.Chrome(binary)\n",
    "\n",
    "# 구글의 이미지 검색 url 받아옴(아무것도 안 쳤을때의 url)\n",
    "browser.get(\"https://www.bing.com/images?FORM=Z9LH\")\n",
    "\n",
    "# 구글의 이미지 검색에 해당하는 input 창의 id 가 '  ?  ' 임(검색창에 해당하는 html코드를 찾아서 elem 사용하도록 설정)\n",
    "# input창 찾는 방법은 원노트에 있음\n",
    "\n",
    "#elem = browser.find_elements_by_class_name('gLFyf gsfi')\n",
    "\n",
    "elem = browser.find_element_by_xpath('//*[@id=\"sb_form_q\"]') \n",
    "\n",
    "\n",
    "\n",
    "########################### 검색어 입력 ###########################\n",
    "\n",
    "# elem 이 input 창과 연결되어 스스로 햄버거를 검색\n",
    "elem.send_keys(\"햄버거\")\n",
    "\n",
    "# 웹에서의 submit 은 엔터의 역할을 함\n",
    "elem.submit()\n",
    "\n",
    "########################### 반복할 횟수 ###########################\n",
    "\n",
    "# 스크롤을 내리려면 브라우져 이미지 검색결과 부분(바디부분)에 마우스 클릭 한번 하고 End키를 눌러야함\n",
    "for i in range(1, 5):\n",
    "    browser.find_element_by_xpath(\"//body\").send_keys(Keys.END)\n",
    "    time.sleep(10)                  # END 키 누르고 내려가는데 시간이 걸려서 sleep 해줌\n",
    "\n",
    "time.sleep(10)                      # 네트워크 느릴까봐 안정성 위해 sleep 해줌\n",
    "html = browser.page_source         # 크롬브라우져에서 현재 불러온 소스 가져옴\n",
    "\n",
    "soup = BeautifulSoup(html, \"lxml\") # html 코드를 검색할 수 있도록 설정\n",
    "\n",
    "########################### 그림파일 저장 ###########################\n",
    "\n",
    "def fetch_list_url():\n",
    "    params = []\n",
    "    imgList = soup.select(\"div > div > a > div > img\")  # 구글 이미지 url 이 있는 img 태그의 _img 클래스에 가서\n",
    "    for im in imgList:\n",
    "        try :\n",
    "            params.append(im[\"src\"])                   # params 리스트에 image url 을 담음\n",
    "        except KeyError:\n",
    "            params.append(im[\"data-src\"])\n",
    "    return params\n",
    "\n",
    "# 이미지의 상세 url 의 값이 있는 src 가 없을 경우\n",
    "# data-src 로 가져오시오 ~ \n",
    "\n",
    "\n",
    "def fetch_detail_url():\n",
    "    params = fetch_list_url()\n",
    "\n",
    "    for idx,p in enumerate(params,1):\n",
    "        # 다운받을 폴더경로 입력\n",
    "        urllib.request.urlretrieve(p, \"C:/bingimages/\" + str(idx) + \".jpg\")\n",
    "\n",
    "# enumerate 는 리스트의 모든 요소를 인덱스와 쌍으로 추출\n",
    "# 하는 함수 . 숫자 1은 인덱스를 1부터 시작해라 ~\n",
    "\n",
    "fetch_detail_url()\n",
    "\n",
    "# 끝나면 브라우져 닫기\n",
    "browser.quit()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
